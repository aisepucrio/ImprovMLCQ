\begin{tabular}{llllllllllllll}
\toprule
Model & Parameters & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & Mean & Std \\
\midrule
XGBClassifier & {'objective': 'binary:logistic', 'base_score': None, 'booster': 'gbtree', 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.7442354016867669, 'device': 'cpu', 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.2266443849254506, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 11, 'max_leaves': None, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 277, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': 6961, 'reg_alpha': 3.5898252740926145e-08, 'reg_lambda': 0.09822594155543213, 'sampling_method': None, 'scale_pos_weight': 6.313326229978378, 'subsample': 0.8070508944841054, 'tree_method': 'auto', 'validate_parameters': None, 'verbosity': 0} & [0.7806, 0.8649, 0.9481, 0.4595, 0.619, 0.4898] & [0.7824, 0.8705, 0.9796, 0.4628, 0.6286, 0.5012] & [0.7998, 0.8788, 0.9833, 0.484, 0.6487, 0.5304] & [0.7862, 0.8735, 0.9759, 0.4671, 0.6318, 0.5063] & [0.7841, 0.8664, 0.961, 0.4642, 0.626, 0.4989] & [0.7865, 0.8524, 0.974, 0.467, 0.6313, 0.506] & [0.7987, 0.8788, 0.9758, 0.4821, 0.6454, 0.5263] & [0.769, 0.838, 0.9759, 0.4477, 0.6138, 0.4796] & [0.806, 0.886, 0.9759, 0.492, 0.6542, 0.5389] & [0.7924, 0.8815, 0.9777, 0.4748, 0.6392, 0.5168] & [0.7886, 0.8691, 0.9727, 0.4701, 0.6338, 0.5094] & [0.0103, 0.0139, 0.0099, 0.0125, 0.0123, 0.0177] \\
LGBMClassifier & {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.015787723031184413, 'max_depth': -1, 'min_child_samples': 7, 'min_child_weight': 0.001, 'min_split_gain': 0.10872415826018969, 'n_estimators': 48, 'n_jobs': -1, 'num_leaves': 143, 'objective': None, 'random_state': 6961, 'reg_alpha': 1.296855105454685e-08, 'reg_lambda': 2.0463329681073517e-09, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.5654465244910241, 'bagging_fraction': 0.8790877043211766, 'bagging_freq': 7} & [0.7824, 0.8745, 0.8924, 0.4594, 0.6066, 0.4767] & [0.783, 0.886, 0.9276, 0.4617, 0.6165, 0.488] & [0.8022, 0.898, 0.9369, 0.4865, 0.6405, 0.5222] & [0.7625, 0.8655, 0.9295, 0.4379, 0.5954, 0.4564] & [0.7803, 0.8865, 0.8998, 0.4571, 0.6062, 0.4755] & [0.8053, 0.889, 0.9405, 0.4903, 0.6446, 0.5281] & [0.799, 0.8925, 0.9368, 0.4818, 0.6364, 0.5165] & [0.7941, 0.8882, 0.9425, 0.4761, 0.6326, 0.5102] & [0.813, 0.9023, 0.9276, 0.5015, 0.651, 0.5383] & [0.7736, 0.8612, 0.9276, 0.4505, 0.6064, 0.473] & [0.7895, 0.8844, 0.9261, 0.4703, 0.6236, 0.4985] & [0.015, 0.0127, 0.016, 0.019, 0.0186, 0.0265] \\
RandomForestClassifier & {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6961, 'verbose': 0, 'warm_start': False} & [0.7346, 0.8677, 0.9481, 0.4108, 0.5732, 0.4214] & [0.7328, 0.8709, 0.9647, 0.4104, 0.5759, 0.4239] & [0.7419, 0.8901, 0.9833, 0.4203, 0.5889, 0.4419] & [0.7283, 0.8808, 0.9722, 0.4068, 0.5736, 0.4198] & [0.7199, 0.885, 0.9722, 0.3994, 0.5662, 0.4086] & [0.7484, 0.8755, 0.9591, 0.4247, 0.5887, 0.444] & [0.7383, 0.8828, 0.9684, 0.4155, 0.5815, 0.4323] & [0.7237, 0.8776, 0.9443, 0.4005, 0.5624, 0.4054] & [0.7477, 0.8922, 0.9647, 0.4248, 0.5899, 0.445] & [0.7369, 0.8806, 0.9555, 0.4137, 0.5774, 0.4269] & [0.7353, 0.8803, 0.9633, 0.4127, 0.5778, 0.4269] & [0.009, 0.0074, 0.0112, 0.0085, 0.009, 0.0133] \\
ExtraTreesClassifier & {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 6961, 'verbose': 0, 'warm_start': False} & [0.6725, 0.8478, 0.9796, 0.3626, 0.5293, 0.3513] & [0.6638, 0.8537, 0.9777, 0.3563, 0.5223, 0.3406] & [0.6606, 0.8707, 0.9981, 0.3563, 0.5251, 0.3431] & [0.6617, 0.866, 0.9852, 0.3557, 0.5226, 0.3404] & [0.6421, 0.8623, 0.9944, 0.3438, 0.511, 0.3213] & [0.6647, 0.8513, 0.9796, 0.3568, 0.5231, 0.342] & [0.6699, 0.8629, 0.9926, 0.3618, 0.5303, 0.352] & [0.6549, 0.8556, 0.9814, 0.3508, 0.5169, 0.3317] & [0.6745, 0.8716, 0.9907, 0.3653, 0.5337, 0.357] & [0.6699, 0.8555, 0.9926, 0.3622, 0.5308, 0.3523] & [0.6635, 0.8597, 0.9872, 0.3572, 0.5245, 0.3432] & [0.0091, 0.0078, 0.007, 0.006, 0.0066, 0.0102] \\
DecisionTreeClassifier & {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 16, 'max_features': 0.5909209333049106, 'max_leaf_nodes': None, 'min_impurity_decrease': 4.09532027495954e-05, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 6961, 'splitter': 'best'} & [0.7447, 0.8689, 0.9184, 0.4184, 0.5749, 0.4269] & [0.7405, 0.8617, 0.8998, 0.4128, 0.5659, 0.4152] & [0.7412, 0.8658, 0.9072, 0.4141, 0.5686, 0.4185] & [0.7412, 0.8726, 0.9369, 0.4163, 0.5765, 0.4274] & [0.7175, 0.8625, 0.8924, 0.3901, 0.5429, 0.3809] & [0.7627, 0.8795, 0.9498, 0.439, 0.6005, 0.4624] & [0.7498, 0.8717, 0.8996, 0.422, 0.5745, 0.4284] & [0.7306, 0.8676, 0.9555, 0.4078, 0.5716, 0.4182] & [0.7676, 0.8776, 0.8794, 0.4409, 0.5874, 0.4494] & [0.7648, 0.8821, 0.9221, 0.4402, 0.5959, 0.4579] & [0.7461, 0.871, 0.9161, 0.4202, 0.5759, 0.4285] & [0.015, 0.0067, 0.0238, 0.0154, 0.0155, 0.0226] \\
\bottomrule
\end{tabular}
