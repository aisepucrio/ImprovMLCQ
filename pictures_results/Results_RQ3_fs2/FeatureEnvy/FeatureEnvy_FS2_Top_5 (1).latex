\begin{tabular}{llllllllllllll}
\toprule
                 Model &                                         Parameters &                                                0 &                                                1 &                                                2 &                                                3 &                                                4 &                                                5 &                                                6 &                                                7 &                                                8 &                                                9 &                                             Mean &                                              Std \\
\midrule
         XGBClassifier & \{'objective': 'binary:logistic', 'base\_score': ... & [0.8713, 0.9292, 0.9961, 0.4112, 0.5821, 0.5211] & [0.8755, 0.9307, 0.9729, 0.4176, 0.5844, 0.5245] &  [0.8877, 0.9378, 0.9884, 0.4443, 0.613, 0.5581] &  [0.8786, 0.9311, 0.969, 0.4237, 0.5896, 0.5309] &  [0.8629, 0.922, 0.9767, 0.3944, 0.5619, 0.4974] &  [0.8824, 0.9338, 0.9883, 0.432, 0.6012, 0.5443] &   [0.8786, 0.9253, 0.9728, 0.423, 0.5896, 0.531] & [0.8636, 0.9239, 0.9883, 0.3956, 0.5651, 0.5012] &  [0.8737, 0.931, 0.9884, 0.4153, 0.5849, 0.5246] &  [0.8737, 0.9254, 0.9845, 0.415, 0.5839, 0.5236] &  [0.8748, 0.929, 0.9825, 0.4172, 0.5856, 0.5257] &  [0.0073, 0.0046, 0.0085, 0.0143, 0.0142, 0.017] \\
        LGBMClassifier & \{'boosting\_type': 'gbdt', 'class\_weight': None,... & [0.8692, 0.9311, 0.9729, 0.4055, 0.5724, 0.5102] &  [0.8706, 0.9347, 0.9302, 0.4047, 0.564, 0.5015] &   [0.8811, 0.94, 0.9147, 0.4252, 0.5806, 0.5218] &  [0.8675, 0.9292, 0.9109, 0.397, 0.5529, 0.4889] &  [0.8664, 0.9256, 0.9574, 0.399, 0.5633, 0.4997] & [0.8807, 0.9347, 0.9339, 0.4248, 0.5839, 0.5254] & [0.8765, 0.9315, 0.9533, 0.4174, 0.5806, 0.5208] & [0.8643, 0.9254, 0.9533, 0.3939, 0.5575, 0.4931] & [0.8723, 0.9323, 0.9767, 0.4118, 0.5793, 0.5183] & [0.8674, 0.9308, 0.9302, 0.3987, 0.5581, 0.4944] & [0.8716, 0.9315, 0.9433, 0.4078, 0.5693, 0.5074] & [0.0056, 0.0041, 0.0217, 0.0109, 0.0108, 0.0128] \\
RandomForestClassifier & \{'bootstrap': True, 'ccp\_alpha': 0.0, 'class\_we... & [0.8162, 0.9139, 0.9264, 0.3199, 0.4756, 0.3946] & [0.8169, 0.9018, 0.9186, 0.3198, 0.4745, 0.3935] & [0.8235, 0.9176, 0.9419, 0.3311, 0.4899, 0.4116] &  [0.7991, 0.9015, 0.8915, 0.2956, 0.444, 0.3571] & [0.8036, 0.9029, 0.9225, 0.3047, 0.4581, 0.3734] &   [0.8238, 0.9158, 0.93, 0.3292, 0.4863, 0.4078] & [0.8175, 0.9002, 0.9066, 0.3183, 0.4712, 0.3902] & [0.8001, 0.9058, 0.9339, 0.3015, 0.4558, 0.3705] &  [0.8133, 0.9144, 0.9302, 0.317, 0.4729, 0.3912] &  [0.807, 0.9044, 0.9147, 0.3077, 0.4605, 0.3765] & [0.8121, 0.9078, 0.9216, 0.3145, 0.4689, 0.3866] & [0.0087, 0.0064, 0.0138, 0.0111, 0.0135, 0.0162] \\
  ExtraTreesClassifier & \{'bootstrap': False, 'ccp\_alpha': 0.0, 'class\_w... &    [0.7548, 0.9086, 1.0, 0.2685, 0.4233, 0.3279] & [0.7551, 0.9073, 0.9961, 0.2683, 0.4227, 0.3273] &    [0.7747, 0.9047, 1.0, 0.2854, 0.4441, 0.3535] & [0.7544, 0.8955, 0.9922, 0.2672, 0.4211, 0.3254] &  [0.7558, 0.908, 0.9961, 0.2688, 0.4234, 0.3282] &   [0.7641, 0.915, 0.9883, 0.274, 0.4291, 0.3358] &    [0.7592, 0.8989, 1.0, 0.2714, 0.4269, 0.3328] &       [0.7488, 0.901, 1.0, 0.2631, 0.4165, 0.32] &    [0.7711, 0.9078, 1.0, 0.2823, 0.4403, 0.3488] &     [0.7516, 0.9027, 1.0, 0.266, 0.4202, 0.3241] &  [0.759, 0.9049, 0.9973, 0.2715, 0.4267, 0.3324] &  [0.008, 0.0053, 0.0039, 0.0068, 0.0084, 0.0103] \\
DecisionTreeClassifier & \{'ccp\_alpha': 0.0, 'class\_weight': None, 'crite... & [0.8385, 0.9083, 0.8605, 0.3421, 0.4895, 0.4141] &   [0.842, 0.9064, 0.8411, 0.345, 0.4893, 0.4146] & [0.8511, 0.9222, 0.9031, 0.3669, 0.5218, 0.4517] & [0.8165, 0.8867, 0.8023, 0.3035, 0.4404, 0.3564] &  [0.835, 0.9054, 0.8643, 0.3374, 0.4853, 0.4088] &     [0.8444, 0.9159, 0.9455, 0.36, 0.5215, 0.45] &  [0.8273, 0.8863, 0.8405, 0.3224, 0.466, 0.3865] & [0.8346, 0.9142, 0.8872, 0.3388, 0.4903, 0.4143] & [0.8364, 0.9124, 0.8488, 0.3374, 0.4829, 0.4064] & [0.8437, 0.9126, 0.9031, 0.3552, 0.5098, 0.4371] &  [0.8369, 0.9071, 0.8696, 0.3409, 0.4897, 0.414] & [0.0092, 0.0112, 0.0388, 0.0174, 0.0235, 0.0272] \\
\bottomrule
\end{tabular}
