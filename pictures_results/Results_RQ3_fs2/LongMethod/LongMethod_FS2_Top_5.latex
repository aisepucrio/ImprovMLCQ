\begin{tabular}{llllllllllllll}
\toprule
                 Model &                                         Parameters &                                                0 &                                                1 &                                                2 &                                                3 &                                                4 &                                                5 &                                                6 &                                                7 &                                                8 &                                                9 &                                             Mean &                                              Std \\
\midrule
         XGBClassifier & \{'objective': 'binary:logistic', 'base\_score': ... & [0.8901, 0.9499, 0.9414, 0.4455, 0.6048, 0.5502] &  [0.8901, 0.942, 0.9844, 0.4476, 0.6154, 0.5616] &    [0.9062, 0.9527, 0.9648, 0.4872, 0.6474, 0.6] & [0.8912, 0.9444, 0.9648, 0.4491, 0.6129, 0.5592] &  [0.8961, 0.9445, 0.9961, 0.462, 0.6312, 0.5799] & [0.8978, 0.9536, 0.9765, 0.4646, 0.6296, 0.5788] & [0.8971, 0.9497, 0.9922, 0.4634, 0.6317, 0.5809] & [0.8999, 0.9501, 0.9529, 0.4691, 0.6287, 0.5785] & [0.8856, 0.9396, 0.9451, 0.4342, 0.5951, 0.5388] &  [0.8932, 0.9411, 0.957, 0.4537, 0.6156, 0.5626] &  [0.8947, 0.9467, 0.9675, 0.4576, 0.6212, 0.569] & [0.0056, 0.0048, 0.0182, 0.0141, 0.0145, 0.0169] \\
        LGBMClassifier & \{'boosting\_type': 'gbdt', 'class\_weight': None,... & [0.8908, 0.9534, 0.9492, 0.4475, 0.6083, 0.5541] & [0.8877, 0.9459, 0.9492, 0.4402, 0.6015, 0.5461] &  [0.9055, 0.9554, 0.9648, 0.4853, 0.6458, 0.598] &   [0.8894, 0.95, 0.9375, 0.4436, 0.6023, 0.5474] &  [0.8943, 0.9506, 0.957, 0.4562, 0.6179, 0.5653] & [0.8988, 0.9573, 0.9569, 0.4665, 0.6272, 0.5766] & [0.8978, 0.9522, 0.9647, 0.4642, 0.6268, 0.5758] & [0.8971, 0.9546, 0.9451, 0.4617, 0.6203, 0.5688] &  [0.8817, 0.9387, 0.8941, 0.4222, 0.5736, 0.515] &  [0.8901, 0.9454, 0.957, 0.4463, 0.6087, 0.5544] & [0.8933, 0.9504, 0.9476, 0.4534, 0.6132, 0.5602] & [0.0064, 0.0053, 0.0196, 0.0165, 0.0184, 0.0213] \\
RandomForestClassifier & \{'bootstrap': True, 'ccp\_alpha': 0.0, 'class\_we... & [0.8622, 0.9493, 0.9727, 0.3909, 0.5577, 0.4931] & [0.8525, 0.9403, 0.9844, 0.3756, 0.5437, 0.4759] & [0.8654, 0.9521, 0.9883, 0.3978, 0.5673, 0.5041] &  [0.8514, 0.9341, 0.9727, 0.3728, 0.539, 0.4706] & [0.8615, 0.9492, 0.9961, 0.3917, 0.5623, 0.4979] & [0.8639, 0.9517, 0.9804, 0.3937, 0.5618, 0.4981] &  [0.858, 0.9485, 0.9961, 0.3848, 0.5552, 0.4897] &  [0.8639, 0.9489, 0.9843, 0.394, 0.5628, 0.4991] &  [0.8447, 0.935, 0.9647, 0.3607, 0.5251, 0.4544] & [0.8562, 0.9433, 0.9883, 0.3822, 0.5512, 0.4848] &  [0.858, 0.9452, 0.9828, 0.3844, 0.5526, 0.4868] & [0.0064, 0.0063, 0.0098, 0.0111, 0.0125, 0.0148] \\
  ExtraTreesClassifier & \{'bootstrap': False, 'ccp\_alpha': 0.0, 'class\_w... &  [0.8228, 0.9451, 0.9766, 0.3324, 0.496, 0.4186] &   [0.8151, 0.9349, 0.9922, 0.3248, 0.4894, 0.41] &  [0.8235, 0.9458, 0.9688, 0.3324, 0.495, 0.4176] & [0.8204, 0.9424, 0.9922, 0.3312, 0.4966, 0.4188] &    [0.8343, 0.9429, 1.0, 0.3502, 0.5187, 0.4454] & [0.8322, 0.9496, 0.9882, 0.3452, 0.5117, 0.4375] &   [0.8255, 0.9417, 0.9843, 0.336, 0.501, 0.4247] & [0.8245, 0.9456, 0.9843, 0.3347, 0.4995, 0.4229] & [0.8119, 0.9314, 0.9725, 0.3179, 0.4792, 0.3986] & [0.8137, 0.9396, 0.9805, 0.3218, 0.4846, 0.4045] &  [0.8224, 0.9419, 0.984, 0.3327, 0.4972, 0.4198] &  [0.007, 0.0052, 0.0092, 0.0094, 0.0112, 0.0134] \\
DecisionTreeClassifier & \{'ccp\_alpha': 0.0, 'class\_weight': None, 'crite... & [0.8682, 0.9341, 0.9336, 0.3983, 0.5584, 0.4952] & [0.8734, 0.9384, 0.8945, 0.4053, 0.5579, 0.4959] & [0.8856, 0.9532, 0.9141, 0.4333, 0.5879, 0.5311] & [0.8619, 0.9325, 0.9336, 0.3867, 0.5469, 0.4814] & [0.8664, 0.9365, 0.9531, 0.3967, 0.5603, 0.4968] &   [0.8678, 0.94, 0.9216, 0.3956, 0.5536, 0.4901] &   [0.8657, 0.941, 0.898, 0.3895, 0.5433, 0.4786] & [0.8643, 0.9369, 0.8784, 0.3849, 0.5352, 0.4696] &   [0.8594, 0.9184, 0.902, 0.3783, 0.533, 0.4661] &  [0.8695, 0.935, 0.8984, 0.3979, 0.5516, 0.4882] & [0.8682, 0.9366, 0.9127, 0.3967, 0.5528, 0.4893] & [0.0069, 0.0082, 0.0215, 0.0143, 0.0147, 0.0173] \\
\bottomrule
\end{tabular}
